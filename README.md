# MVP: Motion Vector Propagation for Zero-Shot Video Object Detection

A novel approach for efficient zero-shot object detection in videos by leveraging motion vectors from compressed video streams combined with OWL-ViT for object detection.

## ğŸ¯ Overview

MVP (Motion Vector Propagation) is a zero-shot object detection framework that combines:
- **Motion Vector Analysis**: Extracts and analyzes motion vectors from H.264/MPEG-4 compressed videos
- **OWL-ViT Integration**: Uses OWL-ViT for zero-shot object detection on keyframes
- **Intelligent Propagation**: Propagates detections across frames using motion vector analysis
- **Efficient Tracking**: Reduces computational overhead by avoiding full detection on every frame

## âœ¨ Key Features

- **Motion Vector Processing**: Efficient extraction and analysis of motion vectors from compressed videos
- **Zero-shot Detection**: OWL-ViT based zero-shot object detection capabilities
- **Smart Propagation**: 9-grid motion vector analysis for accurate object tracking
- **Adaptive Strategy**: Dynamic switching between detection and propagation modes
- **Performance Optimization**: Significant speedup compared to frame-wise detection

## ğŸ—ï¸ Architecture

The framework consists of three main components:

1. **Motion Vector Extractor**: Extracts motion vectors, frame types, and timestamps from compressed videos
2. **OWL-ViT Detector**: Performs zero-shot object detection on keyframes and when needed
3. **Motion Propagation**: Uses 9-grid analysis to propagate detections across frames

## ğŸ“‹ Requirements

```
torch>=1.9.0
torchvision>=0.10.0
transformers>=4.20.0
opencv-python>=4.5.0
numpy>=1.21.0
matplotlib>=3.5.0
tqdm>=4.64.0
PIL>=8.3.0
ffmpeg-python>=0.2.0
```

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone https://github.com/microa/MVP.git
cd MVP
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Install motion vector extractor:
```bash
cd mv-extractor
pip install -e .
```

## ğŸ“Š Dataset Preparation

1. Prepare your video dataset in the following structure:
```
data/
â”œâ”€â”€ videos/           # Video files (.mp4)
â”œâ”€â”€ motion_vectors/   # Extracted motion vectors
â”‚   â””â”€â”€ video_name/
â”‚       â”œâ”€â”€ frame_types.txt
â”‚       â”œâ”€â”€ timestamps.txt
â”‚       â””â”€â”€ motion_vectors/
â”‚           â”œâ”€â”€ mvs-0.npy
â”‚           â”œâ”€â”€ mvs-1.npy
â”‚           â””â”€â”€ ...
â””â”€â”€ ground_truth/     # Ground truth annotations (JSON format)
```

2. Extract motion vectors from videos:
```bash
python utils/extract_motion_vectors.py --video_dir data/videos --output_dir data/motion_vectors
```

## ğŸ”§ Usage

### Basic Usage

```python
from src.mvp_detector import MVPDetector

# Initialize detector
detector = MVPDetector(
    model_id="google/owlv2-large-patch14-ensemble",
    device="cuda"
)

# Process video
results = detector.process_video(
    video_path="path/to/video.mp4",
    motion_vector_dir="path/to/motion_vectors",
    output_dir="path/to/output"
)
```

### Command Line Interface

```bash
# Process single video
python src/main.py --video_path data/videos/video.mp4 --mv_dir data/motion_vectors/video_name --output_dir results/

# Process entire dataset
python src/main.py --video_dir data/videos --mv_root data/motion_vectors --output_root results/
```

### Evaluation

```bash
# Evaluate on dataset
python evaluation/evaluate.py --pred_dir results/ --gt_dir data/ground_truth --output_dir evaluation_results/
```

## ğŸ“ Project Structure

```
MVP/
â”œâ”€â”€ src/                    # Core source code
â”‚   â”œâ”€â”€ mvp_detector.py    # Main MVP detector class
â”‚   â”œâ”€â”€ motion_analyzer.py # Motion vector analysis
â”‚   â”œâ”€â”€ owl_detector.py    # OWL-ViT integration
â”‚   â””â”€â”€ main.py            # Command line interface
â”œâ”€â”€ configs/               # Configuration files
â”‚   â”œâ”€â”€ default.yaml      # Default configuration
â”‚   â””â”€â”€ imagenet_vid.yaml # ImageNet VID specific config
â”œâ”€â”€ evaluation/            # Evaluation scripts
â”‚   â”œâ”€â”€ evaluate.py       # Main evaluation script
â”‚   â””â”€â”€ metrics.py        # Evaluation metrics
â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”œâ”€â”€ extract_motion_vectors.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ data_utils.py
â”œâ”€â”€ examples/              # Usage examples
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â””â”€â”€ custom_dataset.py
â”œâ”€â”€ mv-extractor/          # Motion vector extraction tool
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md             # This file
```

## ğŸ¨ Visualization

The framework includes tools for visualizing motion vectors and detection results:

```bash
# Visualize motion vectors
python utils/visualization.py --mv_dir data/motion_vectors/video_name --output_dir visualizations/

# Visualize detection results
python utils/visualization.py --results_dir results/video_name --output_dir visualizations/
```

## ğŸ“ˆ Results

The MVP framework achieves competitive performance on ImageNet VID dataset with significant speedup:

- **mAP@0.2**: 0.747
- **mAP@0.3**: 0.721  
- **mAP@0.5**: 0.609
- **mAP@[0.5:0.95]**: 0.316

## ğŸ“ Citation

If you use this code in your research, please cite our paper:

```bibtex
@inproceedings{mvp2025,
  title={MVP: Motion Vector Propagation for Zero-Shot Video Object Detection},
  author={Binhua Huang, Ni Wang, Wendong Yao, Soumyabrata Dev},
  booktitle={2025},
  year={2025}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- ImageNet VID dataset creators
- OWL-ViT model by Google Research
- Motion vector extraction tool by LukasBommes
- PyTorch and the open-source community
